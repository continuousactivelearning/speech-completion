{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89521bc5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipywidgets) (9.3.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama\n",
    "!pip install tqdm ipywidgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b15bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ../clustering/intermediate_data/clustered_embeddings.csv\n",
      "Loaded 3474 rows after cleaning and timestamp conversion.\n",
      "Grouped into 368 unique file-cluster segments.\n",
      "\n",
      "Starting title generation with Ollama model: tinyllama:latest\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068f9b253d854c86a386382dd522d511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Titles:   0%|          | 0/368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.notebook import tqdm \n",
    "import ollama \n",
    "import re \n",
    "\n",
    "\n",
    "def convert_timestamp_to_seconds(timestamp_str):\n",
    "    if pd.isna(timestamp_str): \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    timestamp_str = str(timestamp_str).strip()\n",
    "\n",
    "    \n",
    "    parts = list(map(int, timestamp_str.split(':')))\n",
    "\n",
    "    if len(parts) == 2: \n",
    "        minutes, seconds = parts\n",
    "        return float(minutes * 60 + seconds)\n",
    "    elif len(parts) == 3: \n",
    "        hours, minutes, seconds = parts\n",
    "        return float(hours * 3600 + minutes * 60 + seconds)\n",
    "    else:\n",
    "        \n",
    "        print(f\"Warning: Unexpected timestamp format '{timestamp_str}'. Returning None.\")\n",
    "        return None\n",
    "\n",
    "CSV_PATH = \"../clustering/intermediate_data/clustered_embeddings.csv\"\n",
    "OUTPUT_JSON = \"titles_tinyllama.json\"\n",
    "OLLAMA_MODEL_NAME = \"tinyllama:latest\"\n",
    "\n",
    "print(f\"Loading data from: {CSV_PATH}\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "\n",
    "df['start'] = df['start'].apply(convert_timestamp_to_seconds)\n",
    "df['end'] = df['end'].apply(convert_timestamp_to_seconds)\n",
    "\n",
    "df = df[df[\"text\"].notnull() & df[\"cluster\"].notnull() & df[\"start\"].notnull() & df[\"end\"].notnull()]\n",
    "print(f\"Loaded {len(df)} rows after cleaning and timestamp conversion.\")\n",
    "\n",
    "grouped = df.groupby([\"file\", \"cluster\"]).agg({\n",
    "    \"start\": \"min\", \n",
    "    \"end\": \"max\",\n",
    "    \"text\": lambda x: \" \".join(x)\n",
    "}).reset_index()\n",
    "print(f\"Grouped into {len(grouped)} unique file-cluster segments.\")\n",
    "\n",
    "\n",
    "max_length = 256 \n",
    "\n",
    "output = {}\n",
    "\n",
    "print(f\"\\nStarting title generation with Ollama model: {OLLAMA_MODEL_NAME}\")\n",
    "for i, row in tqdm(grouped.iterrows(), total=len(grouped), desc=\"Generating Titles\"):\n",
    "    file = row[\"file\"]\n",
    "    cluster = str(row[\"cluster\"])\n",
    "    \n",
    "    start = row[\"start\"]\n",
    "    end = row[\"end\"]\n",
    "    combined_text = row[\"text\"][:5000] \n",
    "\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant. Please generate a short, human-friendly title for the following transcript segment of an educational lecture. Keep it within 10 words maximum.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Transcript:\\n\\\"\\\"\\\"{combined_text}\\\"\\\"\\\"\\n\\nTitle:\"}\n",
    "    ]\n",
    "\n",
    "    title = \"\" \n",
    "\n",
    "    try:\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model=OLLAMA_MODEL_NAME,\n",
    "            messages=messages,\n",
    "            options={\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.9,\n",
    "                \"num_predict\": max_length\n",
    "            }\n",
    "        )\n",
    "\n",
    "    \n",
    "        if response and 'message' in response and 'content' in response['message']:\n",
    "            generated_content = response['message']['content']\n",
    "            title_parts = generated_content.split(\"Title:\")\n",
    "            if len(title_parts) > 1:\n",
    "                title = title_parts[-1].strip().replace(\"\\n\", \" \")\n",
    "            else:\n",
    "                title = generated_content.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "            if title.startswith('\"') and title.endswith('\"'):\n",
    "                title = title[1:-1]\n",
    "            if title.startswith(\"'\") and title.endswith(\"'\"):\n",
    "                title = title[1:-1]\n",
    "        else:\n",
    "            title = \"Error: Could not parse Ollama response\"\n",
    "            print(f\"\\nWarning: Unexpected Ollama response structure for file {file}, cluster {cluster}. Response: {response}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        title = f\"Error: {type(e).__name__} - {e}\"\n",
    "        print(f\"\\nError generating title for file {file}, cluster {cluster}: {e}\")\n",
    "\n",
    "    if file not in output:\n",
    "        output[file] = {}\n",
    "\n",
    "    output[file][f\"cluster{cluster}\"] = {\n",
    "        \"title\": title,\n",
    "        \"start\": start,\n",
    "        \"end\": end\n",
    "    }\n",
    "\n",
    "\n",
    "print(f\"\\nSaving titles to {OUTPUT_JSON}\")\n",
    "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nProcess completed! Titles saved to {OUTPUT_JSON}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46df681-d456-42cb-9d2a-25250d41ed0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
