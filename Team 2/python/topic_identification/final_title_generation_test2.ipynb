{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c7648-12fc-426f-8e0d-140323921eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved\\Desktop\\Speech-Completition-Prediction\\python\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ved\\Desktop\\Speech-Completition-Prediction\\python\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "# --- Config ---\n",
    "CSV_PATH = \"../clustering/intermediate_data/embeddings_added.csv\"\n",
    "OUTPUT_CSV = \"incremental_topic_titles.csv\"\n",
    "TARGET_FILE = \"210.json\"\n",
    "OLLAMA_MODEL = \"phi3:mini\"  # or \"phi:latest\" if using that\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "TOP_N_KEYWORDS = 5\n",
    "SIMILARITY_THRESHOLD = 0.35\n",
    "MAX_INPUT_CHARS = 3000\n",
    "\n",
    "# --- Setup ---\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "kw_model = KeyBERT(model=embedding_model)\n",
    "\n",
    "def extract_keywords(text, top_n=TOP_N_KEYWORDS):\n",
    "    keywords = kw_model.extract_keywords(text, top_n=top_n, stop_words=\"english\")\n",
    "    return [kw for kw, _ in keywords]\n",
    "\n",
    "def compute_similarity(keywords1, keywords2):\n",
    "    texts = [' '.join(keywords1), ' '.join(keywords2)]\n",
    "    vec = TfidfVectorizer().fit_transform(texts)\n",
    "    return cosine_similarity(vec[0:1], vec[1:2])[0][0]\n",
    "\n",
    "def generate_title_with_requests(text, keywords):\n",
    "    text = text[:MAX_INPUT_CHARS]\n",
    "    prompt = f\"\"\"\n",
    "You are an expert teacher helping generate section titles for lecture videos.\n",
    "\n",
    "Suggest a short, human-friendly TITLE for this section of transcript.\n",
    "\n",
    "Keywords: {', '.join(keywords)}\n",
    "\n",
    "Transcript:\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\n",
    "Only return the title. No explanation.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            OLLAMA_URL,\n",
    "            json={\"model\": OLLAMA_MODEL, \"prompt\": prompt, \"stream\": False},\n",
    "        )\n",
    "        title = response.json().get(\"response\", \"\").strip()\n",
    "        if not title:\n",
    "            title = \"Untitled (Empty response)\"\n",
    "        return title\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] while generating title: {e}\")\n",
    "        return f\"Error - {type(e).__name__}\"\n",
    "\n",
    "# --- Load & Filter ---\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df[df[\"file\"] == TARGET_FILE]\n",
    "df = df[df[\"text\"].notnull() & df[\"text\"].str.strip().astype(bool)]\n",
    "df = df.sort_values(\"start\").reset_index(drop=True)\n",
    "\n",
    "# --- Track topics ---\n",
    "results = []\n",
    "\n",
    "current_topic_chunks = []\n",
    "current_topic_keywords = []\n",
    "\n",
    "i = 0\n",
    "while i < len(df):\n",
    "    row = df.iloc[i]\n",
    "    text = row[\"text\"]\n",
    "    start = row[\"start\"]\n",
    "\n",
    "    if len(current_topic_chunks) < 5 and not current_topic_keywords:\n",
    "        current_topic_chunks.append(text)\n",
    "        current_topic_keywords.extend(extract_keywords(text))\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    current_keywords = extract_keywords(text)\n",
    "    similarity = compute_similarity(current_topic_keywords, current_keywords)\n",
    "\n",
    "    if similarity >= SIMILARITY_THRESHOLD:\n",
    "        current_topic_chunks.append(text)\n",
    "        current_topic_keywords.extend(current_keywords)\n",
    "        i += 1\n",
    "    else:\n",
    "        combined_text = \" \".join(current_topic_chunks)\n",
    "        title = generate_title_with_requests(combined_text, current_topic_keywords)\n",
    "\n",
    "        results.append({\n",
    "            \"file\": TARGET_FILE,\n",
    "            \"start\": df.iloc[i - len(current_topic_chunks)][\"start\"],\n",
    "            \"title\": title\n",
    "        })\n",
    "\n",
    "        current_topic_chunks = [text]\n",
    "        current_topic_keywords = current_keywords\n",
    "        i += 1\n",
    "\n",
    "# Handle final topic\n",
    "if current_topic_chunks:\n",
    "    combined_text = \" \".join(current_topic_chunks)\n",
    "    title = generate_title_with_requests(combined_text, current_topic_keywords)\n",
    "    results.append({\n",
    "        \"file\": TARGET_FILE,\n",
    "        \"start\": df.iloc[len(df) - len(current_topic_chunks)][\"start\"],\n",
    "        \"title\": title\n",
    "    })\n",
    "\n",
    "# --- Save ---\n",
    "output_df = pd.DataFrame(results)\n",
    "output_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"\\nSaved to {OUTPUT_CSV}\")\n",
    "print(output_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SpeechEnvDocker)",
   "language": "python",
   "name": "speechenvdocker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
